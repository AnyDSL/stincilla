fn set_pixeli16_fn(img: Imgi16) -> fn(i32, i16) -> () { |idx, val| bitcast[&mut[1][i16]](img.buf.data)(idx) = val }
fn get_pixeli16_fn(img: Imgi16) -> fn(i32) -> i16 { |idx| bitcast[&[1][i16]](img.buf.data)(idx) }

fn for_shift_down(a: i32, b: i32, body: fn(i32) -> ()) -> () {
    if a > b {
        body(a);
        for_shift_down(a >> 1, b, body, return)
    }
}
fn for_shift_up(a: i32, b: i32, body: fn(i32) -> ()) -> () {
    if a < b {
        body(a);
        for_shift_up(a << 1, b, body, return)
    }
}

fn iteration1f1i(out: Img, arr: Imgi16, bh_lower: BoundaryFni16, bh_upper: BoundaryFni16,
                 body: fn(i32, i32, Acc, Acci16) -> ()
                ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img    (acc.alloc(acc.dev(), out.width * out.height * sizeof[f32]()), out.width, out.height);
    let arr_gpu = get_img_i16(acc.alloc(acc.dev(), arr.width * arr.height * sizeof[i16]()), arr.width, arr.height);
    copy(arr.buf, arr_gpu.buf, arr.width * arr.height * sizeof[i16]());

    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let gid_x = acc.gidx();
            let gid_y = acc.tidy() + acc.bdimy() * acc.bidy() * unroll;
            let out_acc = get_acc(out_gpu, set_pixel_fn(out_gpu), get_pixel_fn(out_gpu));
            let arr_acc = get_acci16_bh(arr_gpu, set_pixeli16_fn(arr_gpu), get_pixeli16_fn(arr_gpu), 10, bh_lower, bh_upper);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc.bdimy(), out_acc, arr_acc);
            }
        }
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * sizeof[f32]());
    release(out_gpu.buf);
    release(arr_gpu.buf);
}
fn iteration2i(out: Imgi16, arr: Imgi16, bh_lower: BoundaryFni16, bh_upper: BoundaryFni16,
               body: fn(i32, i32, Acci16, Acci16) -> ()
              ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(acc.alloc(acc.dev(), out.width * out.height * sizeof[i16]()), out.width, out.height);
    let arr_gpu = get_img_i16(acc.alloc(acc.dev(), arr.width * arr.height * sizeof[i16]()), arr.width, arr.height);
    copy(arr.buf, arr_gpu.buf, arr.width * arr.height * sizeof[i16]());

    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let gid_x = acc.gidx();
            let gid_y = acc.tidy() + acc.bdimy() * acc.bidy() * unroll;
            let out_acc = get_acci16(out_gpu, set_pixeli16_fn(out_gpu), get_pixeli16_fn(out_gpu));
            let arr_acc = get_acci16_bh(arr_gpu, set_pixeli16_fn(arr_gpu), get_pixeli16_fn(arr_gpu), 10, bh_lower, bh_upper);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc.bdimy(), out_acc, arr_acc);
            }
        }
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * sizeof[i16]());
    release(out_gpu.buf);
    release(arr_gpu.buf);
}
fn iteration2i1m(out: Imgi16, img: Imgi16, map: Img, bh_lower: BoundaryFni16, bh_upper: BoundaryFni16,
                 body: fn(i32, i32, Acci16, Acci16, Acc) -> ()
                ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(acc.alloc(acc.dev(), out.width * out.height * sizeof[i16]()), out.width, out.height);
    let img_gpu = get_img_i16(acc.alloc(acc.dev(), img.width * img.height * sizeof[i16]()), img.width, img.height);
    let map_gpu = get_img    (acc.alloc(acc.dev(), map.width * map.height * sizeof[f32]()), map.width, map.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * sizeof[i16]());
    copy(map.buf, map_gpu.buf, map.width * map.height * sizeof[f32]());

    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let gid_x = acc.gidx();
            let gid_y = acc.tidy() + acc.bdimy() * acc.bidy() * unroll;
            let out_acc = get_acci16(out_gpu, set_pixeli16_fn(out_gpu), get_pixeli16_fn(out_gpu));
            let img_acc = get_acci16_bh(img_gpu, set_pixeli16_fn(img_gpu), get_pixeli16_fn(img_gpu), 10, bh_lower, bh_upper);
            let map_acc = get_acc(map_gpu, set_pixel_fn(map_gpu), get_pixel_fn(map_gpu));

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc.bdimy(), out_acc, img_acc, map_acc);
            }
        }
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * sizeof[i16]());
    release(out_gpu.buf);
    release(img_gpu.buf);
    release(map_gpu.buf);
}
fn iteration3i(out: Imgi16, img: Imgi16, tmp: Imgi16,
               body: fn(i32, i32, Acci16, Acci16, Acci16) -> ()
              ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(acc.alloc(acc.dev(), out.width * out.height * sizeof[i16]()), out.width, out.height);
    let img_gpu = get_img_i16(acc.alloc(acc.dev(), img.width * img.height * sizeof[i16]()), img.width, img.height);
    let tmp_gpu = get_img_i16(acc.alloc(acc.dev(), tmp.width * tmp.height * sizeof[i16]()), tmp.width, tmp.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * sizeof[i16]());
    copy(tmp.buf, tmp_gpu.buf, tmp.width * tmp.height * sizeof[i16]());

    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let gid_x = acc.gidx();
            let gid_y = acc.tidy() + acc.bdimy() * acc.bidy() * unroll;
            let out_acc = get_acci16(out_gpu, set_pixeli16_fn(out_gpu), get_pixeli16_fn(out_gpu));
            let img_acc = get_acci16(img_gpu, set_pixeli16_fn(img_gpu), get_pixeli16_fn(img_gpu));
            let tmp_acc = get_acci16(tmp_gpu, set_pixeli16_fn(tmp_gpu), get_pixeli16_fn(tmp_gpu));

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc.bdimy(), out_acc, img_acc, tmp_acc);
            }
        }
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * sizeof[i16]());
    release(out_gpu.buf);
    release(img_gpu.buf);
    release(tmp_gpu.buf);
}
fn reduce(img: Imgi16, body: fn(i32, i32, Acci16) -> i32) -> i32 {
    let tmp_buf = acc.alloc(acc.dev(), sizeof[i32]());
    let tmp     = bitcast[&mut[1][i32]](tmp_buf.data);
    let sum_buf = alloc_cpu(sizeof[i32]());
    bitcast[&mut[i32]](sum_buf.data)(0) = 0;
    copy(sum_buf, tmp_buf, sizeof[i32]());

    let img_gpu = get_img_i16(acc.alloc(acc.dev(), img.width * img.height * sizeof[i16]()), img.width, img.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * sizeof[i16]());

    let grid  = (img_gpu.width, 1, 1);
    let block = (128, 1, 1);
    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let tid = acc.tidx();
            let sm_sum = reserve_shared[i32](128);
            let mut sum = 0;
            let img_acc = get_acci16(img_gpu, set_pixeli16_fn(img_gpu), get_pixeli16_fn(img_gpu));
            for y in $range(0, img_gpu.height) @{
                sum += body(acc.gidx(), y, img_acc);
            }
            sm_sum(tid) = sum;

            for o in @for_shift_down(128 >> 1, 0) {
                acc.barrier();
                if tid < o @{
                    sm_sum(tid) += sm_sum(tid + o);
                }
            }

            acc.barrier();

            if tid == 0 {
                atomic_add_global(&mut tmp(0), sm_sum(0));
            }
        }
    }

    copy(tmp_buf, sum_buf, sizeof[i32]());
    let sum = bitcast[&[i32]](sum_buf.data)(0) / iter_acc;
    release(sum_buf);
    release(tmp_buf);
    release(img_gpu.buf);
    sum
}
fn histogram(img: Img, body: fn(i32, i32, Acc) -> i32) -> Buffer {
    let hist_buf = acc.alloc(acc.dev(), 256 * sizeof[i32]());
    let     hist = bitcast[&mut[1][i32]](hist_buf.data);

    let img_gpu = get_img(acc.alloc(acc.dev(), img.width * img.height * sizeof[f32]()), img.width, img.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * sizeof[f32]());

    let grid  = (img.width, 1, 1);
    let block = (256, 1, 1);
    for benchmark_acc() {
        with acc.exec(acc.dev(), (256, 1, 1), (64, 1, 1)) @{
            hist(acc.gidx()) = 0;
        }
        with acc.exec(acc.dev(), grid, block) @{
            let sm_hist = reserve_shared[i32](256);
            let img_acc = get_acc(img_gpu, set_pixel_fn(img_gpu), get_pixel_fn(img_gpu));
            for y in $range(0, img.height) @{
                let bin = body(acc.gidx(), y, img_acc);
                atomic_add_shared(&mut sm_hist(bin), 1);
            }
            atomic_add_global(&mut hist(acc.tidx()), sm_hist(acc.tidx()));
        }
    }

    hist_buf
}
fn inclusive_scan(hist_buf: Buffer, size: i32) -> Buffer {
    let scan_buf = acc.alloc(acc.dev(), size * sizeof[i32]());
    let     scan = bitcast[&mut[1][i32]](scan_buf.data);
    let     hist = bitcast[&   [1][i32]](hist_buf.data);

    // perform scan per block in shared memory first
    let block_size = if size <= 256 { 128 } else { 256 };
    let num_blocks = size / (2 * block_size);
    let tmp_buf = acc.alloc(acc.dev(), num_blocks * sizeof[i32]());
    let     tmp = bitcast[&mut[1][i32]](tmp_buf.data);

    let grid  = (size / 2, 1, 1);
    let block = (block_size, 1, 1);

    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            let gid = acc.gidx();
            let tid = acc.tidx();
            let sm_size = 2 * block_size;
            let sm_tmp = reserve_shared[i32](sm_size);

            // load input into shared memory
            sm_tmp(2 * tid)     = hist(2 * gid);
            sm_tmp(2 * tid + 1) = hist(2 * gid + 1);

            let mut offset = 1;
            for d in for_shift_down(sm_size >> 1, 0) @{ // build sum in place up the tree
                acc.barrier();
                if tid < d @{
                    let ai = offset * (2 * tid + 1) - 1;
                    let bi = offset * (2 * tid + 2) - 1;
                    sm_tmp(bi) += sm_tmp(ai);
                }
                offset *= 2;
            }

            // clear the last element: exclusive scan only
            // if tid == 0 { sm_tmp(sm_size - 1) = 0; }

            // traverse down tree & build scan
            for d in for_shift_up(1, sm_size) @{
                offset >>= 1;
                acc.barrier();
                if tid < d @{
                    let ai = offset * (2 * tid + 1) - 1;
                    let bi = offset * (2 * tid + 2) - 1;
                    let tmp = sm_tmp(ai);
                    sm_tmp(ai) = sm_tmp(bi);
                    sm_tmp(bi) += tmp;
                }
            }

            acc.barrier();

            // write results to device memory
            if tid == 0 @{
                tmp(acc.bidx()) = sm_tmp(sm_size - 1);
            }
            scan(2 * gid)     = sm_tmp(2 * tid);
            scan(2 * gid + 1) = sm_tmp(2 * tid + 1);
        }
    }

    if num_blocks > 1 {
        // perform scan on block scan results
        let grid1  = (num_blocks, 1, 1);
        let block1 = (num_blocks, 1, 1);
        for benchmark_acc() {
            with acc.exec(acc.dev(), grid1, block1) @{
                let tid = acc.tidx();
                let sm_size = num_blocks;
                let sm_tmp = reserve_shared[i32](sm_size);

                // load input into shared memory
                sm_tmp(tid) = tmp(tid);

                acc.barrier();

                if tid == 0 @{
                    let mut sum = sm_tmp(0);
                    for d in range(1, sm_size) {
                        sum += sm_tmp(d);
                        sm_tmp(d) = sum;
                    }
                }

                acc.barrier();

                // write results to device memory
                tmp(tid) = sm_tmp(tid);
            }
        }

        // add block scan results to array
        let grid2  = ((num_blocks-1) * block_size, 1, 1);
        let block2 = (block_size, 1, 1);
        for benchmark_acc() {
            with acc.exec(acc.dev(), grid2, block2) @{
                let tid = acc.tidx();
                let gid = acc.gidx() + block_size; // first block holds already the correct scan results
                let sm_tmp = reserve_shared[i32](1);

                if tid == 0 @{
                    sm_tmp(0) = tmp(acc.bidx());
                }

                acc.barrier();

                // write results to device memory
                scan(gid) += sm_tmp(0); // TODO: compensate for iter_acc
            }
        }
    }

    release(tmp_buf);
    scan_buf
}
fn find_position(scan_buf: Buffer, mut size: i32, body: fn(i32) -> i32) -> i32 {
    let size_buf = Buffer { device : 0, data : bitcast[&[i8]](&mut size) };
    let pos_buf  = acc.alloc(acc.dev(), sizeof[i32]());
    let pos      = bitcast[&mut[1][i32]](pos_buf.data);
    let scan     = bitcast[&   [1][i32]](scan_buf.data);
    copy(size_buf, pos_buf, sizeof[i32]());

    let grid  = (size, 1, 1);
    let block = (256, 1, 1);
    for benchmark_acc() {
        with acc.exec(acc.dev(), grid, block) @{
            if body(scan(acc.gidx())) != 0 @{
                atomic_min_global(&mut pos(0), acc.gidx());
            }
        }
    }

    let mut result:i32;
    let r_buf = Buffer { device : 0, data : bitcast[&[i8]](&mut result) };
    copy(pos_buf, r_buf, sizeof[i32]());
    release(pos_buf);
    result
}
